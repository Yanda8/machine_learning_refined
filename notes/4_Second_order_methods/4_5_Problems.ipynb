{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Second order methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Two fundamental problems with Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's method is a powerful algorithm that makes enormous progress towards at each step (unlike e.g., zero and first order methods that can require a huge number of steps to make equal progress).   However Newton's method suffers from two fundmanetal problems that limit its popularity in certain fields of machine learning, which we discuss here.  These problems involve its application to minimizing non-convex functions, and issues scaling with input dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "# import standard tools\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import autograd.numpy as np\n",
    "import time\n",
    "\n",
    "# import custom plotting tools\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "from mlrefined_libraries import calculus_library as callib\n",
    "\n",
    "static_plotter = optlib.static_plotter.Visualizer();\n",
    "anime_plotter = optlib.animation_plotter.Visualizer();\n",
    "optimizers = optlib.optimizers\n",
    "\n",
    "# the next three lines are needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.1  Application to minimizing non-convex functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As discussed in the previous Section, Newton's method can behave very badly when applied to minimizing non-convex functions.  Since each step is based off of the second order approximation to a function, if the curvature at a point is *convcave* Newton's method will naturally take a *step uphill*.  \n",
    " \n",
    "On the other hand because the second order approximation used by Newton's method contains so much local information than e.g., an analagous first order step, when applied to convex functions Newton's method can converge to a global minimum in far fewer steps - particularly when it is close to a minimum (since often the quadratic approximation matches a convex functions locally very well). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.2  Scaling limitations of Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Newton's method step requires far more in terms of storage and computation than a first order step - requiring the storage and computation of not just a gradient but an entire $N\\times N$ Hessian matrix of second derivative information as well.  Simply storing the Hessian for a single step of Newton's method, with its $N^2$ entries, can quickly become challenging for what moderately sized input.  For example if the input to a function has dimension $N = 10,000$ the corresponding $10,000 \\times 10,000$ Hessian matrix has $10,000^2 = 100,000,000$ entries.  The kind of functions used in machine learning applications can easily have tens of thousands to hundreds of thousands or even hundreds of millions of inputs, making the complete storage of an associated Hessian impossible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "398px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
