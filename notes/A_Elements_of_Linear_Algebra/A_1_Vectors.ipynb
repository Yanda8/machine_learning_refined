{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A: Elements of Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.1 Vectors and vector operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "#imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "from mlrefined_libraries import basics_library as baslib\n",
    "from mlrefined_libraries import linear_algebra_library as linlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector is another word for an ordered listing of numbers. For example, the following\n",
    "\n",
    "\\begin{equation}\n",
    "\\left[-3, \\, \\, 4, \\, \\, 1\\right]\n",
    "\\end{equation}\n",
    "\n",
    "is a vector of three *elements* or *entries*, also referred to as a vector of *length* or *dimension* three. In general a vector can have an arbitrary number of elements, and can contain numbers, variables, or both. For example,\n",
    "\n",
    "\\begin{equation}\n",
    "\\left[x_1, \\,\\, x_2, \\,\\, x_3, \\,\\, x_4\\right]\n",
    "\\end{equation}\n",
    "\n",
    "is a vector of four variables. When numbers or variables are listed out horizontally (or in a row), we call the resulting vector a *row* vector. Notice, we can also list them just as well vertically (or in a column) in which case we refer to the resulting vector as a *column* vector. For example, the following \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "-3  \\\\\n",
    "4 \\\\\n",
    "1\n",
    "\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "is a column vector of length three. We can swap back and forth between a row and column version of a vector by *transposing* it. Transposition is usually denoted by a superscript $^{T}$ placed just to the right and above a vector, and simply turns a row vector into an equivalent column vector and vice versa. For example, we can write\n",
    "\n",
    "\\begin{equation}\n",
    "{\\begin{bmatrix}\n",
    "-3  \\\\\n",
    "4 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}}^{\\,T}\n",
    "= [-3, \\, \\, 4, \\, \\, 1]\\qquad \\text{and} \\qquad \n",
    "[-3, \\, \\, 4, \\, \\, 1]^{\\,T} = \n",
    "{\\begin{bmatrix}\n",
    "-3 \\\\\n",
    "4 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discuss vectors more generally we use algebraic notation, typically a bold lowercase (often English) letter, e.g., $\\mathbf{x}$. The transpose of $\\mathbf{x}$ is then denoted as $\\mathbf{x}^{T}$. This notation does not denote whether or not the vector is a row or column, or how many elements it contains. Such information must therefore be given explicitly. Throughout the text, unless stated otherwise, we assume all vectors are column vectors.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric interpretation of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors of length two (or three) are easy to intuit since they live in two (or three) dimensional spaces that are familiar to our human senses. For example, the two dimensional vector\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} = \n",
    "\\begin{bmatrix}\n",
    "-1  \\\\\n",
    "2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "can be drawn in a two dimensional plane as an arrow stemming from the origin and ending at the point whose horizontal and vertical coordinates  are $-3$ and $4$ respectively, as illustrated in the left panel of Figure below. We call this the *arrow perspective*. As shown in the right panel of Figure below $\\mathbf{x}$ can alternatively be drawn (and thought of) as a single data point, i.e., the arrow's endpoint. When plotting a low dimensional dataset (a collection of vectors or data points) we often employ the latter, which we call the *point perspective*.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../../mlrefined_images/linear_algebra_images/two_perspectives.png\" width=\"60%\"/>\n",
    "</figure>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector addition and subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add and subtract two vectors element-wise, with just one catch: in order to add/subtract two vectors they must have the same number of elements (or dimension), and both must be row or column vectors. For example, vectors $\\mathbf{x}$ and $\\mathbf{y}$ (both column vectors of length $N$)  \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} = {\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\\\\\n",
    "\\vdots \\\\\n",
    "x_N \\\\\n",
    "\\end{bmatrix}} \\,\\,\\,\\,\\,\\,\\,\\,\\,  \\mathbf{y} = {\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2\\\\\n",
    "\\vdots \\\\\n",
    "y_N \\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}\n",
    "\n",
    "are added element-wise to form\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} + \\mathbf{y} = {\\begin{bmatrix}\n",
    "x_1 + y_1 \\\\\n",
    "x_2 + y_2\\\\\n",
    "\\vdots \\\\\n",
    "x_N + y_N \\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtraction is defined similarly\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} - \\mathbf{y} = {\\begin{bmatrix}\n",
    "x_1 - y_1 \\\\\n",
    "x_2 - y_2\\\\\n",
    "\\vdots \\\\\n",
    "x_N - y_N \\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric interpretation of vector addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the *arrow perspective* on vectors, the addition of two vectors is (nicely) equal to the vector representing the far corner of the parallelogram formed by the two vectors in the sum. This is called the *parallelogram law*, and is illustrated in Figure below for two input vectors colored black, with their sum shown in red. The dashed lines here are merely visual guides helping to outline the parallelogram underlying the sum.\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../../mlrefined_images/linear_algebra_images/addition.png\" width=\"30%\"/>\n",
    "</figure>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication of a vector by a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can multiply any vector $\\mathbf{x}$ by a scalar $c$ by treating the multiplication element-wise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "c\\,\\mathbf{x} = {\\begin{bmatrix}\n",
    "c\\,x_1 \\\\\n",
    "c\\,x_2\\\\\n",
    "\\vdots \\\\\n",
    "c\\, x_N \\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise product of two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of ways to multiply two vectors, perhaps the most natural of which is the element-wise product. The element-wise product, sometimes called the Hadamard product, works precisely how it sounds: we multiply two vectors of the same dimension element-by-element. Note that just like addition, we need both vectors to have the same dimension in order to make this work. \n",
    "\n",
    "The element-wise product of two vectors $\\mathbf{x}$ and $\\mathbf{y}$ is written notationally as $\\mathbf{x} \\circ \\mathbf{y}$  \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} \\circ \\mathbf{y} = {\\begin{bmatrix}\n",
    "x_1y_1 \\\\\n",
    "x_2y_2\\\\\n",
    "\\vdots \\\\\n",
    "x_Ny_N \\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner product of two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inner product (also referred to as the dot product) is another way to multiply two vectors of the same dimension. Unlike the element-wise product, the inner product of two vectors produces a scalar output. To take the inner product of two vectors we first multiply them together element-wise, and simply add up the elements in the resulting vector.\n",
    "\n",
    "The inner product of vectors $\\mathbf{x}$ and $\\mathbf{y}$ is written as $\\mathbf{x}^T \\mathbf{y}$\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}^T \\mathbf{y} =x_{1}y_{1}+x_{2}y_{2}+\\cdots x_{N}y_{N} = \\sum_{n=1}^Nx_ny_n\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Pythagorean theorem* provides a useful way to measure the length of a vector in two dimensions. As shown in Fifure below, using the Pythagorean theorem we can treat the general two dimensional vector\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} = {\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}\n",
    "\n",
    "as the hypotenuse of a right triangle, and write\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{length of } \\mathbf{x} = \\sqrt{x_1^2 + x_2^2}\n",
    "\\end{equation}\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../../mlrefined_images/linear_algebra_images/pythagorean.png\" width=\"30%\"/>\n",
    "</figure>   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we can express the length of $\\mathbf{x}$ in terms of the inner product of $\\mathbf{x}$ with itself, as \n",
    "\n",
    "\\begin{equation}\n",
    "\\sqrt{x_1^2 + x_2^2} = \\sqrt{\\mathbf{x}^T\\mathbf{x}}\n",
    "\\end{equation}\n",
    "\n",
    "and this generalizes to vectors of any length. Using the notation $\\lVert \\mathbf{x} \\rVert _2$ to denote the length of an $N$ dimensional vector $\\mathbf{x}$, we can write it as \n",
    "\n",
    "\\begin{equation}\n",
    "\\lVert \\mathbf{x} \\rVert _2 = \\sqrt{\\sum_{n=1}^Nx_n^2} = \\sqrt{\\mathbf{x}^T\\mathbf{x}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see in Section A.4 the notion of length for vectors can be defined in a number of ways, the one discussed here being just one (and the most popular).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric interpretation of the inner product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inner product of two vectors $\\mathbf{x}$ and $\\mathbf{y}$  \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}^T \\mathbf{y} = \\sum_{n=1}^Nx_ny_n\n",
    "\\end{equation}\n",
    "\n",
    "can be expressed in terms of the lengths of $\\mathbf{x}$ and $\\mathbf{y}$, via the so-called *inner product rule*\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}^T\\mathbf{y} = \\lVert \\mathbf{x} \\rVert_2\\, \\lVert \\mathbf{y} \\rVert_2\\, \\text{cos}(\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\theta$ is the angle between $\\mathbf{x}$ and $\\mathbf{y}$. This rule is perhaps best intuited after a slight rearrangement of its terms, as\n",
    "\n",
    "\\begin{equation}\n",
    "\\left(\\frac{\\mathbf{x}}{ \\lVert \\mathbf{x} \\rVert_2}\\right)^T \\left(\\frac{\\mathbf{y}}{ \\lVert \\mathbf{y} \\rVert_2} \\right)= \\text{cos}(\\theta)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where each input vector is now normalized to have unit length. Notice that because cosine lies between $-1$ and $+1$ so too does the inner product of any two unit-length vectors. When the two vectors point in the exact same direction the value takes on $+1$, when they point in completely opposite directions, $-1$. When the two vectors are *perpendicular* to each other, their inner product is equal to zero. See Figure below. \n",
    "\n",
    "<figure>\n",
    "    <img src=\"../../mlrefined_images/linear_algebra_images/angle.png\" width=\"60%\"/>\n",
    "</figure>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer product of two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outer product is another way to define multiplication between two vectors. With two column vectors $\\mathbf{x}$ and $\\mathbf{y}$ (of not necessarily the same dimension)\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}=\\begin{bmatrix}\n",
    "x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{N}\n",
    "\\end{bmatrix}\\,\\,\\,\\,\\,\\,\\,\\mathbf{y}=\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{M}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "their outer product is written as $\\mathbf{x}\\mathbf{y}^T$ and is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}\\mathbf{y}^{T}=\\begin{bmatrix}\n",
    "x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{N}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{M}\n",
    "\\end{bmatrix}^{T}=\\begin{bmatrix}\n",
    "x_{1}y_{1} & x_{1}y_{2} & \\cdots & x_{1}y_{M}\\\\\n",
    "x_{2}y_{1} & x_{2}y_{2} & \\cdots & x_{2}y_{M}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_{N}y_{1} & x_{N}y_{2} & \\cdots & x_{N}y_{M}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "The result is an $N\\times M$ matrix, which can be thought of as a collection of $M$ column vectors of length $N$ stacked side-by-side (or likewise, as a collection of $N$ row vectors of length $M$ stacked one on top of each other). We will discuss matrices further in the next Section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear combination is an operation that generalizes simple addition of two vectors by combining addition and scalar multiplication. Given two vectors $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ of the same dimension, their linear combination is formed by multiplying each with a scalar first and then adding up the result, as in    \n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha_{1}\\mathbf{x}_{1}+\\alpha_{2}\\mathbf{x}_{2}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha_{1}$ and $\\alpha_{2}$ are real numbers. Notice that for a given set of values for $\\alpha_{1}$ and $\\alpha_{2}$, the linear combination is a vector itself with the same dimension as $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$. In Figure below we show the linear combination of vectors\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}_1 = {\\begin{bmatrix}\n",
    "2 \\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}} \\,\\,\\,\\,\\,\\,\\,\\,\\,  \\mathbf{x}_2 = {\\begin{bmatrix}\n",
    "-1 \\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "for three different set of values for $\\alpha_1$ and $\\alpha_2$. As you can see in Figure below by changing the values of $\\alpha_{1}$ and $\\alpha_{2}$ in $\\alpha_{1}\\mathbf{x}_{1}+\\alpha_{2}\\mathbf{x}_{2}$ we get a new vector each time (shown in red).  \n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../../mlrefined_images/linear_algebra_images/lin_comb_1.png\" width=\"80%\"/>\n",
    "</figure>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of all such vectors (or points) created by taking a linear combination of vectors $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ is referred to as the span of $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{span of } \\mathbf{x}_1 \\text{ and } \\mathbf{x}_2 = \\left\\{\\alpha_{1}\\mathbf{x}_{1}+\\alpha_{2}\\mathbf{x}_{2}\\,|\\, \\alpha_1, \\alpha_2 \\in \\mathbb{R} \\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "In the example above the span of vectors $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ is the entire two-dimensional plane, or put in different words, $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ span the two-dimensional plane. Notice, the span of two two-dimensional vectors is not necessarily always the entire two-dimensional plane. Take the two vectors \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}_1 = {\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}} \\,\\,\\,\\,\\,\\,\\,\\,\\,  \\mathbf{x}_2 = {\\begin{bmatrix}\n",
    "2 \\\\\n",
    "2\\\\\n",
    "\\end{bmatrix}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "for example. Because these two vectors point at the same direction (one is a scalar multiple of the other), any linear combination of the two will have the same direction (See Figure below). In this case the span of $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ is no longer the entire two-dimensional plane, but a one-dimensional line that can be traced out using scalar multiples of any of the two vectors. In other words, given either one of $\\mathbf{x}_{1}$ or $\\mathbf{x}_{2}$ the other one becomes redundant. In linear algebra terms, such vectors are called *linearly dependent*.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../../mlrefined_images/linear_algebra_images/lin_comb_2.png\" width=\"80%\"/>\n",
    "</figure>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notion of linear combination of vectors can be extended in general to a set of $k$ vectors $\\left\\{\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots,\\mathbf{x}_{k}\\right\\}$, all of the same dimension, taking the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^k \\alpha_{i}\\mathbf{x}_{i}=\\alpha_{1}\\mathbf{x}_{1}+\\alpha_{2}\\mathbf{x}_{2}+\\cdots+\\alpha_{k}\\mathbf{x}_{k}\n",
    "\\end{equation}\n",
    "\n",
    "If these vectors span a $k$-dimensional space they are called *linearly independent*. Otherwise, there is at least one vector in the set that can be written as a linear combination of the rest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; This material is not to be distributed, copied, or reused without written permission from the authors."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "509px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
